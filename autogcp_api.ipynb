{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyIve-wav4ls",
        "outputId": "0d7b3f8c-b27e-4de8-ad40-41dfc02d6464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ultralytics/ultralytics.git@main\n",
            "  Cloning https://github.com/ultralytics/ultralytics.git (to revision main) to /tmp/pip-req-build-b7j2keff\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ultralytics/ultralytics.git /tmp/pip-req-build-b7j2keff\n",
            "  Resolved https://github.com/ultralytics/ultralytics.git to commit e248e5b5062844ff358f8e754692cd1889efde56\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.94) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.94) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.94) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.94) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.94) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.94) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.94) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.94) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.94) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.94) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.94) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.94) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.94) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.94) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics==8.3.94)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.94) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.94) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.94) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.94) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.94) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.94) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.94) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.3.94) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.3.94) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.94) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.94) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.94) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.94) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.94) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.94) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.94) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.94) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.94) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics==8.3.94)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics==8.3.94)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics==8.3.94)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics==8.3.94)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics==8.3.94)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics==8.3.94)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics==8.3.94)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics==8.3.94)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics==8.3.94)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.94) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.94) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.94) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics==8.3.94)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.94) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.94) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics==8.3.94) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.3.94) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics==8.3.94) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Building wheels for collected packages: ultralytics\n",
            "  Building wheel for ultralytics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ultralytics: filename=ultralytics-8.3.94-py3-none-any.whl size=949753 sha256=66bc94b64181521b1c074a1cea2af01c97591a57e580aea1fc4bed832a37c2d2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-iy7vzs2q/wheels/ce/28/0b/747d53a7fba3579e3367c6a4b40abf971babc68f7a46b16a28\n",
            "Successfully built ultralytics\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.94 ultralytics-thop-2.0.14\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyexiftool\n",
            "  Downloading PyExifTool-0.5.6-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyproj in /usr/local/lib/python3.11/dist-packages (3.7.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting flask-cors\n",
            "  Downloading flask_cors-5.0.1-py3-none-any.whl.metadata (961 bytes)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyproj) (2025.1.31)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2.3.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyExifTool-0.5.6-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Downloading flask_cors-5.0.1-py3-none-any.whl (11 kB)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok, pyexiftool, numpy, flask-ngrok, flask-cors\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ultralytics 8.3.94 requires numpy<=2.1.1,>=1.23.0, but you have numpy 2.2.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flask-cors-5.0.1 flask-ngrok-0.0.25 numpy-2.2.4 pyexiftool-0.5.6 pyngrok-7.2.3\n",
            "\u001b[32mINFO\u001b[0m[03-22|14:25:54] no configuration paths supplied \n",
            "\u001b[36mDBUG\u001b[0m[03-22|14:25:54] ngrok config file at legacy location does not exist \u001b[36mlegacy_path\u001b[0m=/root/.config/ngrok/ngrok.yml\n",
            "\u001b[32mINFO\u001b[0m[03-22|14:25:54] using configuration at default config path \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml\n",
            "\u001b[32mINFO\u001b[0m[03-22|14:25:54] open config file                         \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml \u001b[32merr\u001b[0m=nil\n",
            "No update available, this is the latest version.\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'libimage-exiftool-perl' instead of 'exiftool'\n",
            "The following additional packages will be installed:\n",
            "  libarchive-zip-perl libmime-charset-perl libsombok3 libunicode-linebreak-perl\n",
            "Suggested packages:\n",
            "  libposix-strptime-perl libencode-hanextra-perl libpod2-base-perl\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-zip-perl libimage-exiftool-perl libmime-charset-perl libsombok3\n",
            "  libunicode-linebreak-perl\n",
            "0 upgraded, 5 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 3,964 kB of archives.\n",
            "After this operation, 23.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libarchive-zip-perl all 1.68-1 [90.2 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libimage-exiftool-perl all 12.40+dfsg-1 [3,717 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmime-charset-perl all 1.012.2-1 [30.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libsombok3 amd64 2.4.0-2 [26.9 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libunicode-linebreak-perl amd64 0.0.20190101-1build3 [99.1 kB]\n",
            "Fetched 3,964 kB in 3s (1,487 kB/s)\n",
            "Selecting previously unselected package libarchive-zip-perl.\n",
            "(Reading database ... 126209 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-zip-perl_1.68-1_all.deb ...\n",
            "Unpacking libarchive-zip-perl (1.68-1) ...\n",
            "Selecting previously unselected package libimage-exiftool-perl.\n",
            "Preparing to unpack .../libimage-exiftool-perl_12.40+dfsg-1_all.deb ...\n",
            "Unpacking libimage-exiftool-perl (12.40+dfsg-1) ...\n",
            "Selecting previously unselected package libmime-charset-perl.\n",
            "Preparing to unpack .../libmime-charset-perl_1.012.2-1_all.deb ...\n",
            "Unpacking libmime-charset-perl (1.012.2-1) ...\n",
            "Selecting previously unselected package libsombok3:amd64.\n",
            "Preparing to unpack .../libsombok3_2.4.0-2_amd64.deb ...\n",
            "Unpacking libsombok3:amd64 (2.4.0-2) ...\n",
            "Selecting previously unselected package libunicode-linebreak-perl.\n",
            "Preparing to unpack .../libunicode-linebreak-perl_0.0.20190101-1build3_amd64.deb ...\n",
            "Unpacking libunicode-linebreak-perl (0.0.20190101-1build3) ...\n",
            "Setting up libsombok3:amd64 (2.4.0-2) ...\n",
            "Setting up libarchive-zip-perl (1.68-1) ...\n",
            "Setting up libimage-exiftool-perl (12.40+dfsg-1) ...\n",
            "Setting up libmime-charset-perl (1.012.2-1) ...\n",
            "Setting up libunicode-linebreak-perl (0.0.20190101-1build3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/ultralytics/ultralytics.git@main\n",
        "!pip install --upgrade opencv-python numpy pyexiftool pyproj flask flask-ngrok flask-cors pyngrok gdown\n",
        "!ngrok update\n",
        "!ngrok authtoken '' #put your token here\n",
        "!apt-get install exiftool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTCAGDoBv4lt",
        "outputId": "e4df309c-a17d-4387-8f82-4d5e5eb1c67b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BsR-fh5GASwgiyroj1bTj9JC51XEufLO\n",
            "To: /content/model_yolo11_50ep_v2.pt\n",
            "100%|██████████| 5.33M/5.33M [00:00<00:00, 80.8MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Ngrok tunnel available at: NgrokTunnel: \"https://656f-34-143-191-215.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:30:15] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:30:16] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:36:13] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:07] \"POST /upload HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:08] \"POST /upload HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:16] \"POST /upload HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:16] \"POST /upload HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:24] \"POST /upload HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:24] \"POST /upload HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:32] \"POST /upload HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:32] \"POST /upload HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:40] \"POST /upload HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:40] \"POST /upload HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Ultralytics 8.3.94 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\n",
            "0: 3648x5472 (no detections), 197.7ms\n",
            "Speed: 51.1ms preprocess, 197.7ms inference, 256.1ms postprocess per image at shape (1, 3, 3648, 5472)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:51] \"POST /predict/92becfc3-a9fe-4052-9cd9-86338776c199 HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 3648x5472 (no detections), 235.3ms\n",
            "Speed: 50.7ms preprocess, 235.3ms inference, 107.3ms postprocess per image at shape (1, 3, 3648, 5472)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:51] \"POST /predict/d7bc6191-7b67-42f5-a02d-c5ff74b316d4 HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "0: 3648x5472 3 gcps, 185.0ms\n",
            "Speed: 51.0ms preprocess, 185.0ms inference, 368.4ms postprocess per image at shape (1, 3, 3648, 5472)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:53] \"POST /predict/5ea432dc-a9fc-49b9-90b7-cd415d00583c HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 3648x5472 3 gcps, 183.5ms\n",
            "Speed: 50.9ms preprocess, 183.5ms inference, 113.6ms postprocess per image at shape (1, 3, 3648, 5472)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:54] \"POST /predict/2cab3465-f524-447a-a65a-f02e91a70195 HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "0: 3648x5472 1 gcp, 184.0ms\n",
            "Speed: 51.2ms preprocess, 184.0ms inference, 122.5ms postprocess per image at shape (1, 3, 3648, 5472)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:55] \"POST /predict/1cbb5195-108c-436f-85d6-7623fbc114b4 HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 3648x5472 1 gcp, 184.3ms\n",
            "Speed: 51.7ms preprocess, 184.3ms inference, 124.1ms postprocess per image at shape (1, 3, 3648, 5472)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:55] \"POST /predict/1d62476b-09d7-4666-8a15-92ebefde48d2 HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "0: 3648x5472 2 gcps, 181.6ms\n",
            "Speed: 51.0ms preprocess, 181.6ms inference, 127.3ms postprocess per image at shape (1, 3, 3648, 5472)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:57] \"POST /predict/6cff2789-84a4-4d82-84f6-6522319feb67 HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 3648x5472 2 gcps, 184.5ms\n",
            "Speed: 52.7ms preprocess, 184.5ms inference, 113.0ms postprocess per image at shape (1, 3, 3648, 5472)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:57] \"POST /predict/9c403af1-c4e6-4baa-99ae-8b045c76981b HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "0: 3648x5472 2 gcps, 184.3ms\n",
            "Speed: 51.2ms preprocess, 184.3ms inference, 107.4ms postprocess per image at shape (1, 3, 3648, 5472)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:58] \"POST /predict/c43c173a-9eaf-428a-b1a4-28210a97019a HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 3648x5472 2 gcps, 185.1ms\n",
            "Speed: 51.0ms preprocess, 185.1ms inference, 107.5ms postprocess per image at shape (1, 3, 3648, 5472)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 14:37:59] \"POST /predict/54b27100-c32e-44e6-8ef7-5e5425029602 HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "from flask import Flask, jsonify, request\n",
        "import torch\n",
        "import gc\n",
        "import os\n",
        "import uuid\n",
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "from pyproj import Transformer, CRS\n",
        "import math\n",
        "from ultralytics import YOLO\n",
        "from pyngrok import ngrok\n",
        "import gdown\n",
        "import subprocess\n",
        "import re\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Camera Parameters for DJI FC6310\n",
        "camera_params = {\n",
        "    \"focal_length\": 8.8,  # in mm\n",
        "    \"sensor_size\": (13.2, 8.8),  # in mm\n",
        "    \"image_size\": (5472, 3648),  # in pixels\n",
        "}\n",
        "\n",
        "# Define model path\n",
        "MODEL_PATH = \"model_yolo11_50ep_v2.pt\"\n",
        "\n",
        "# Google Drive file ID (extract from the link)\n",
        "GDRIVE_FILE_ID = \"1BsR-fh5GASwgiyroj1bTj9JC51XEufLO\"\n",
        "MODEL_URL = f\"https://drive.google.com/uc?id={GDRIVE_FILE_ID}\"\n",
        "\n",
        "# Check if model exists, if not, download it\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    logging.info(\"Downloading YOLO model from Google Drive...\")\n",
        "    try:\n",
        "        gdown.download(MODEL_URL, MODEL_PATH, quiet=False)\n",
        "        logging.info(\"YOLO model downloaded successfully.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to download YOLO model: {e}\")\n",
        "        raise\n",
        "\n",
        "# Load the model\n",
        "try:\n",
        "    model = YOLO(MODEL_PATH)\n",
        "    logging.info(\"YOLO model loaded successfully\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error loading YOLO model: {e}\")\n",
        "    raise\n",
        "\n",
        "# Path to store uploaded images\n",
        "UPLOAD_FOLDER = \"images/\"\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
        "\n",
        "def process_image_with_yolo(image_path, model, patch_size=640, stride=640):\n",
        "    large_image = cv2.imread(image_path)\n",
        "    if large_image is None:\n",
        "        logging.error(f\"Failed to load {image_path}\")\n",
        "        return None\n",
        "\n",
        "    # Convert BGR to RGB\n",
        "    large_image = cv2.cvtColor(large_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Convert image to a float32 PyTorch tensor\n",
        "    image_tensor = torch.from_numpy(large_image).float().permute(2, 0, 1).unsqueeze(0) / 255.0\n",
        "\n",
        "    # Run inference using YOLO 11\n",
        "    results = model(image_tensor)\n",
        "\n",
        "    # Extract detection results\n",
        "    global_centers = []\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            x_center, y_center, _, _ = box.xywh[0].tolist()\n",
        "            global_centers.append([int(x_center), int(y_center)])\n",
        "\n",
        "    logging.info(f\"Detections for {image_path}: {len(global_centers)} objects found\")\n",
        "    return [os.path.basename(image_path), global_centers]\n",
        "\n",
        "def get_metadata(file_path):\n",
        "    filename = os.path.basename(file_path)\n",
        "    all_metadata = {'filename': filename}\n",
        "\n",
        "    try:\n",
        "        # Run exiftool as a shell command\n",
        "        result = subprocess.run([\"exiftool\", \"-json\", file_path], capture_output=True, text=True)\n",
        "\n",
        "        if result.returncode != 0:\n",
        "            raise Exception(f\"ExifTool error: {result.stderr}\")\n",
        "\n",
        "        # Parse JSON output\n",
        "        metadata_list = json.loads(result.stdout)\n",
        "        if metadata_list:\n",
        "            all_metadata.update(metadata_list[0])  # ExifTool returns a list\n",
        "\n",
        "        return all_metadata\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error retrieving metadata from {file_path}: {e}\")\n",
        "        return {'error': str(e)}\n",
        "\n",
        "def convert_gps_to_decimal(gps_value):\n",
        "    \"\"\"Convert GPS coordinates from degrees, minutes, and seconds to decimal format.\"\"\"\n",
        "    try:\n",
        "        if isinstance(gps_value, (int, float)):  # Already in correct format\n",
        "            return float(gps_value)\n",
        "\n",
        "        parts = str(gps_value).replace(\" deg\", \"\").replace(\"'\", \"\").replace('\"', \"\").split()\n",
        "        degrees, minutes, seconds = map(float, parts[:3])\n",
        "        decimal_value = degrees + (minutes / 60) + (seconds / 3600)\n",
        "\n",
        "        # If 'S' or 'W' is in the original string, make it negative\n",
        "        if \"S\" in gps_value or \"W\" in gps_value:\n",
        "            decimal_value = -decimal_value\n",
        "\n",
        "        return decimal_value\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error converting GPS value {gps_value}: {e}\")\n",
        "        return None  # Return None if conversion fails\n",
        "\n",
        "def extract_numeric_value(value):\n",
        "    \"\"\"Extracts numeric value from a string like '221.9 m Above Sea Level'.\"\"\"\n",
        "    try:\n",
        "        match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", str(value))  # Find numeric part\n",
        "        if match:\n",
        "            return float(match.group(0))  # Convert extracted number to float\n",
        "        else:\n",
        "            raise ValueError(f\"Could not extract numeric value from '{value}'\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error extracting numeric value from '{value}': {e}\")\n",
        "        return None  # Return None if conversion fails\n",
        "\n",
        "def calculate_gsd(sensor_size, image_size, altitude, focal_length):\n",
        "    gsd_x = (sensor_size[0] * altitude) / (image_size[0] * focal_length)\n",
        "    gsd_y = (sensor_size[1] * altitude) / (image_size[1] * focal_length)\n",
        "    return gsd_x, gsd_y\n",
        "\n",
        "def calculate_rotated_points(center, gcp_list, rotation_angle=0):\n",
        "    rotation_angle_rad = np.deg2rad(rotation_angle)\n",
        "    rotated_points = [{'type': 'center', 'longitude': center[0], 'latitude': center[1]}]\n",
        "    for i, gcp in enumerate(gcp_list):\n",
        "        rotated_gcp_x = (gcp[2] - center[0]) * np.cos(rotation_angle_rad) - (gcp[1] - center[1]) * np.sin(rotation_angle_rad) + center[0]\n",
        "        rotated_gcp_y = (gcp[2] - center[0]) * np.sin(rotation_angle_rad) + (gcp[1] - center[1]) * np.cos(rotation_angle_rad) + center[1]\n",
        "        rotated_points.append({'type': f'GCP {i+1}', 'longitude': rotated_gcp_x, 'latitude': rotated_gcp_y})\n",
        "    return rotated_points\n",
        "\n",
        "def scale_and_translate_polygon(points, average_ratio, image_width, image_height):\n",
        "    new_center = [image_width / 2, image_height / 2]\n",
        "    original_center = next(p for p in points if p['type'] == 'center')\n",
        "    dx = new_center[0] - original_center['longitude']\n",
        "    dy = new_center[1] - original_center['latitude']\n",
        "    translated_points = []\n",
        "    for point in points:\n",
        "        if point['type'] == 'center':\n",
        "            translated_points.append({'type': 'center', 'longitude': point['longitude'] + dx, 'latitude': point['latitude'] + dy})\n",
        "        else:\n",
        "            distance_x = point['longitude'] - original_center['longitude']\n",
        "            distance_y = point['latitude'] - original_center['latitude']\n",
        "            scaled_distance_x = distance_x * average_ratio\n",
        "            scaled_distance_y = distance_y * average_ratio\n",
        "            translated_gcp_x = original_center['longitude'] + scaled_distance_x + dx\n",
        "            translated_gcp_y = image_height - (original_center['latitude'] + scaled_distance_y + dy)\n",
        "            translated_points.append({'type': point['type'], 'longitude': translated_gcp_x, 'latitude': translated_gcp_y})\n",
        "    return translated_points\n",
        "\n",
        "def map_points_to_nearest_gcp(translated_points, gcps, gcp_list, img_width, img_height, max_distance=200):\n",
        "    mapped_points = {}\n",
        "    excluded_types = ['center']\n",
        "    gcp_data = {int(item[0][3:]): {'latitude': item[1], 'longitude': item[2], 'altitude': item[3], 'name': item[0]} for item in gcp_list}\n",
        "    for point in translated_points:\n",
        "        if point['type'] in excluded_types:\n",
        "            continue\n",
        "        gcp_num = int(''.join(filter(str.isdigit, point['type'])))\n",
        "        gcp_info = gcp_data.get(gcp_num)\n",
        "        min_distance = float('inf')\n",
        "        nearby_gcps = []\n",
        "        for gcp in gcps:\n",
        "            distance = np.linalg.norm(np.array([point['longitude'], point['latitude']]) - np.array(gcp))\n",
        "            if distance <= max_distance:\n",
        "                nearby_gcps.append(gcp)\n",
        "                if distance < min_distance:\n",
        "                    min_distance = distance\n",
        "        if 0 <= point['longitude'] < img_width and 0 <= point['latitude'] < img_height:\n",
        "            if nearby_gcps and gcp_info:\n",
        "                closest_gcp = min(nearby_gcps, key=lambda g: np.linalg.norm(np.array([point['longitude'], point['latitude']]) - np.array(g)))\n",
        "                mapped_points[gcp_info['name']] = {\"x\": int(closest_gcp[0]), \"y\": int(closest_gcp[1])}\n",
        "            elif min_distance > max_distance and gcp_info:\n",
        "                mapped_points[gcp_info['name']] = {\"x\": int(point['longitude']), \"y\": int(point['latitude'])}\n",
        "    return mapped_points\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def home():\n",
        "    with torch.no_grad():\n",
        "      torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    torch.cuda.ipc_collect()\n",
        "    return \"Flask server is running successfully via Ngrok!\"\n",
        "\n",
        "# Endpoint for uploading a user picture\n",
        "# Dictionary to store original filenames mapped to UUIDs\n",
        "\n",
        "filename_map = {}\n",
        "\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload_image():\n",
        "    if 'file' not in request.files:\n",
        "        logging.error(\"No file part in the request\")\n",
        "        return jsonify({'error': 'No file part'}), 400\n",
        "\n",
        "    file = request.files['file']\n",
        "\n",
        "    if file.filename == '':\n",
        "        logging.error(\"No selected file\")\n",
        "        return jsonify({'error': 'No selected file'}), 400\n",
        "\n",
        "    if file:\n",
        "        try:\n",
        "            image_uuid = str(uuid.uuid4())\n",
        "            original_filename = file.filename\n",
        "            filename = f\"{image_uuid}.jpg\"\n",
        "            file_path = os.path.join(UPLOAD_FOLDER, filename)\n",
        "            file.save(file_path)\n",
        "            filename_map[image_uuid] = original_filename\n",
        "            logging.info(f\"File {original_filename} uploaded successfully as {filename}\")\n",
        "            return jsonify({'message': 'File uploaded successfully', 'image_uuid': image_uuid}), 200\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error saving file: {e}\")\n",
        "            return jsonify({'error': str(e)}), 500\n",
        "\n",
        "@app.route('/predict/<image_uuid>', methods=['POST'])\n",
        "def run_prediction(image_uuid):\n",
        "    image_path = os.path.join(UPLOAD_FOLDER, f\"{image_uuid}.jpg\")\n",
        "\n",
        "    if not os.path.exists(image_path):\n",
        "        logging.error(f\"Image with UUID {image_uuid} not found\")\n",
        "        return jsonify({'error': 'Image not found'}), 404\n",
        "\n",
        "    # Expect JSON body with gcp_list and crs\n",
        "    data = request.get_json()\n",
        "    if not data or 'gcp_list' not in data:\n",
        "        logging.error(\"GCP list not provided in request body\")\n",
        "        return jsonify({'error': 'GCP list required in JSON body'}), 400\n",
        "\n",
        "    gcp_list = data['gcp_list']  # e.g., [[\"gcp01\", 1854440.881, 627710.620, 43.215], ...]\n",
        "    crs_epsg = data.get('crs', 'EPSG:32647')  # Default to Zone 47N if not provided\n",
        "\n",
        "    try:\n",
        "        # Process image with YOLO\n",
        "        detection_result = process_image_with_yolo(image_path, model)\n",
        "        if not detection_result:\n",
        "            original_filename = filename_map.get(image_uuid, f\"{image_uuid}.jpg\")\n",
        "            result = {\"filename\": original_filename, \"gcps\": {}}\n",
        "            logging.info(f\"No detections for {image_path}\")\n",
        "            return jsonify(result), 200\n",
        "\n",
        "        filename, gcps_cv_list = detection_result\n",
        "        original_filename = filename_map.get(image_uuid, filename)\n",
        "\n",
        "        # Process metadata\n",
        "        gps_metadata = get_metadata(image_path)\n",
        "        img_width = gps_metadata['ImageWidth']\n",
        "        img_height = gps_metadata['ImageHeight']\n",
        "        flight_height = float(gps_metadata.get(\"RelativeAltitude\", 120.0))\n",
        "        gsd_x, gsd_y = calculate_gsd(camera_params[\"sensor_size\"], camera_params[\"image_size\"], flight_height, camera_params[\"focal_length\"])\n",
        "        average_ratio = 1 / gsd_x\n",
        "\n",
        "        yaw = math.radians(float(gps_metadata.get(\"CameraYaw\", 0)))\n",
        "        north_orientation = float(gps_metadata.get(\"CameraYaw\", 0))\n",
        "\n",
        "        # Define CRS\n",
        "        crs_geo = CRS(\"EPSG:4326\").to_3d()  # Geographic coordinates from image metadata\n",
        "        crs_utm = CRS(crs_epsg).to_3d()     # User-specified CRS (e.g., UTM zone)\n",
        "\n",
        "        # Get image center coordinates and always convert to the specified CRS\n",
        "        latitude = convert_gps_to_decimal(gps_metadata.get(\"GPSLatitude\"))\n",
        "        longitude = convert_gps_to_decimal(gps_metadata.get(\"GPSLongitude\"))\n",
        "        altitude = extract_numeric_value(gps_metadata.get(\"GPSAltitude\", 120.0))  # Default to 120m if missing\n",
        "\n",
        "        transformer = Transformer.from_crs(crs_geo, crs_utm, always_xy=True)\n",
        "        utm_x, utm_y, utm_z = transformer.transform(longitude, latitude, altitude)\n",
        "        center = (utm_x, utm_y)\n",
        "\n",
        "        # Process GCPs (assumed to be in the same CRS as crs_epsg, e.g., UTM)\n",
        "        rotated_points = calculate_rotated_points(center, gcp_list, north_orientation)\n",
        "        translated_points = scale_and_translate_polygon(rotated_points, average_ratio, img_width, img_height)\n",
        "\n",
        "        mapped_points = map_points_to_nearest_gcp(translated_points, gcps_cv_list, gcp_list, img_width, img_height)\n",
        "\n",
        "        result = {\n",
        "            \"filename\": original_filename,\n",
        "            \"gcps\": mapped_points\n",
        "        }\n",
        "\n",
        "        logging.info(f\"Prediction successful for image {image_path} with CRS {crs_epsg}\")\n",
        "        return jsonify(result), 200\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error processing prediction: {e}\")\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "@app.route(\"/clear\", methods=[\"DELETE\"])\n",
        "def clear_images():\n",
        "    try:\n",
        "        # Get list of files in UPLOAD_FOLDER\n",
        "        files = os.listdir(UPLOAD_FOLDER)\n",
        "        for file in files:\n",
        "            file_path = os.path.join(UPLOAD_FOLDER, file)\n",
        "            if os.path.isfile(file_path) and file.endswith('.jpg'):\n",
        "                os.remove(file_path)\n",
        "                logging.info(f\"Deleted file: {file}\")\n",
        "\n",
        "        # Clear the filename_map\n",
        "        filename_map.clear()\n",
        "        logging.info(\"All images cleared and filename_map reset\")\n",
        "        return jsonify({\"message\": \"All uploaded images cleared successfully\"}), 200\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error clearing images: {e}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Start ngrok tunnel\n",
        "    public_url = ngrok.connect(5000, \"http\")\n",
        "    print(f\" * Ngrok tunnel available at: {public_url}\")\n",
        "\n",
        "    # Run Flask app\n",
        "    app.run(port=5000, threaded=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
